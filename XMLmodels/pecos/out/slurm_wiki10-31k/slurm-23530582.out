05/02/2024 13:12:27 - INFO - __main__ - Setting random seed 0
05/02/2024 13:12:27 - INFO - __main__ - Loaded training feature matrix with shape=(14146, 101938)
05/02/2024 13:12:27 - INFO - __main__ - Loaded training label matrix with shape=(14146, 30938)
05/02/2024 13:12:28 - INFO - __main__ - Loaded 14146 training sequences
05/02/2024 13:12:32 - INFO - pecos.xmc.xtransformer.model - Hierarchical label tree: [128, 2048, 30938]
05/02/2024 13:12:32 - INFO - pecos.xmc.xtransformer.model - Fine-tune Transformers with nr_labels=[128, 2048, 30938]
05/02/2024 13:12:32 - INFO - pecos.xmc.xtransformer.model - Fine-tuning XR-Transformer with tfn+man at level 0, nr_labels=128, avr_M_nnz=128
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|██████████| 570/570 [00:00<00:00, 233kB/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 21.1kB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 22.6MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 78.9MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   2%|▏         | 10.5M/440M [00:00<00:04, 96.9MB/s]model.safetensors:   7%|▋         | 31.5M/440M [00:00<00:03, 110MB/s] model.safetensors:  12%|█▏        | 52.4M/440M [00:00<00:03, 114MB/s]model.safetensors:  17%|█▋        | 73.4M/440M [00:00<00:03, 115MB/s]model.safetensors:  21%|██▏       | 94.4M/440M [00:00<00:02, 116MB/s]model.safetensors:  26%|██▌       | 115M/440M [00:01<00:02, 116MB/s] model.safetensors:  31%|███       | 136M/440M [00:01<00:02, 117MB/s]model.safetensors:  36%|███▌      | 157M/440M [00:01<00:02, 117MB/s]model.safetensors:  40%|████      | 178M/440M [00:01<00:02, 117MB/s]model.safetensors:  45%|████▌     | 199M/440M [00:01<00:02, 117MB/s]model.safetensors:  50%|████▉     | 220M/440M [00:01<00:01, 117MB/s]model.safetensors:  55%|█████▍    | 241M/440M [00:02<00:01, 117MB/s]model.safetensors:  60%|█████▉    | 262M/440M [00:02<00:01, 117MB/s]model.safetensors:  64%|██████▍   | 283M/440M [00:02<00:01, 117MB/s]model.safetensors:  69%|██████▉   | 304M/440M [00:02<00:01, 117MB/s]model.safetensors:  74%|███████▍  | 325M/440M [00:02<00:00, 117MB/s]model.safetensors:  79%|███████▊  | 346M/440M [00:02<00:00, 117MB/s]model.safetensors:  83%|████████▎ | 367M/440M [00:03<00:00, 117MB/s]model.safetensors:  88%|████████▊ | 388M/440M [00:03<00:00, 117MB/s]model.safetensors:  93%|█████████▎| 409M/440M [00:03<00:00, 117MB/s]model.safetensors:  98%|█████████▊| 430M/440M [00:03<00:00, 117MB/s]model.safetensors: 100%|██████████| 440M/440M [00:03<00:00, 117MB/s]
05/02/2024 13:12:40 - INFO - pecos.xmc.xtransformer.matcher - Downloaded bert-base-uncased model from s3.
05/02/2024 13:12:40 - INFO - pecos.xmc.xtransformer.matcher - ***** Encoding data len=14146 truncation=256*****
05/02/2024 13:12:53 - INFO - pecos.xmc.xtransformer.matcher - ***** Finished with time cost=12.876407623291016 *****
05/02/2024 13:13:02 - INFO - pecos.xmc.xtransformer.matcher - trn tensors saved to /scratch/slurm_tmpdir/job_23530582/tmpc0pu12t2/X_trn.pt
05/02/2024 13:13:02 - INFO - pecos.utils.torch_util - Setting device to cuda, number of active GPUs: 1
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher - Start fine-tuning transformer matcher...
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
/home/ul/ul_student/ul_ruw26/.local/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher - ***** Running training *****
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Num examples = 14146
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Num labels = 128
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Num Epochs = 3
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Learning Rate Schedule = linear
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Batch size = 32
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Gradient Accumulation steps = 1
05/02/2024 13:13:26 - INFO - pecos.xmc.xtransformer.matcher -   Total optimization steps = 1000
05/02/2024 13:13:55 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][    50/  1000] |   49/ 443 batches | ms/batch 477.4188 | train_loss 9.777567e-01 | lr 2.500000e-05
05/02/2024 13:14:11 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   100/  1000] |   99/ 443 batches | ms/batch 306.2217 | train_loss 4.654887e-01 | lr 5.000000e-05
05/02/2024 13:14:27 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   150/  1000] |  149/ 443 batches | ms/batch 308.5670 | train_loss 3.838973e-01 | lr 4.722222e-05
05/02/2024 13:14:43 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   200/  1000] |  199/ 443 batches | ms/batch 309.8835 | train_loss 3.344387e-01 | lr 4.444444e-05
05/02/2024 13:14:43 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t at global_step 200 ****
05/02/2024 13:14:44 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:15:00 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   250/  1000] |  249/ 443 batches | ms/batch 311.1999 | train_loss 3.050309e-01 | lr 4.166667e-05
05/02/2024 13:15:17 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   300/  1000] |  299/ 443 batches | ms/batch 312.5148 | train_loss 2.908817e-01 | lr 3.888889e-05
05/02/2024 13:15:33 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   350/  1000] |  349/ 443 batches | ms/batch 313.4385 | train_loss 2.749389e-01 | lr 3.611111e-05
05/02/2024 13:15:50 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   400/  1000] |  399/ 443 batches | ms/batch 314.2326 | train_loss 2.737701e-01 | lr 3.333333e-05
05/02/2024 13:15:50 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t at global_step 400 ****
05/02/2024 13:15:50 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:16:10 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   450/  1000] |    6/ 443 batches | ms/batch 309.1519 | train_loss 2.591828e-01 | lr 3.055556e-05
05/02/2024 13:16:26 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   500/  1000] |   56/ 443 batches | ms/batch 314.8416 | train_loss 2.546116e-01 | lr 2.777778e-05
05/02/2024 13:16:43 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   550/  1000] |  106/ 443 batches | ms/batch 315.5399 | train_loss 2.518338e-01 | lr 2.500000e-05
05/02/2024 13:17:00 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   600/  1000] |  156/ 443 batches | ms/batch 315.8362 | train_loss 2.548783e-01 | lr 2.222222e-05
05/02/2024 13:17:00 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t at global_step 600 ****
05/02/2024 13:17:00 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:17:17 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   650/  1000] |  206/ 443 batches | ms/batch 316.0679 | train_loss 2.486589e-01 | lr 1.944444e-05
05/02/2024 13:17:34 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   700/  1000] |  256/ 443 batches | ms/batch 316.4762 | train_loss 2.448264e-01 | lr 1.666667e-05
05/02/2024 13:17:50 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   750/  1000] |  306/ 443 batches | ms/batch 316.6790 | train_loss 2.384545e-01 | lr 1.388889e-05
05/02/2024 13:18:07 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   800/  1000] |  356/ 443 batches | ms/batch 316.6136 | train_loss 2.450247e-01 | lr 1.111111e-05
05/02/2024 13:18:07 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t at global_step 800 ****
05/02/2024 13:18:08 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:18:24 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   850/  1000] |  406/ 443 batches | ms/batch 316.5811 | train_loss 2.404745e-01 | lr 8.333333e-06
05/02/2024 13:18:44 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][   900/  1000] |   13/ 443 batches | ms/batch 311.0270 | train_loss 2.379508e-01 | lr 5.555556e-06
05/02/2024 13:19:01 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][   950/  1000] |   63/ 443 batches | ms/batch 316.6189 | train_loss 2.308207e-01 | lr 2.777778e-06
05/02/2024 13:19:18 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][  1000/  1000] |  113/ 443 batches | ms/batch 316.6197 | train_loss 2.338231e-01 | lr 0.000000e+00
05/02/2024 13:19:18 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t at global_step 1000 ****
05/02/2024 13:19:18 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:19:19 - INFO - pecos.xmc.xtransformer.matcher - Reload the best checkpoint from /scratch/slurm_tmpdir/job_23530582/tmp1r6ifj4t
05/02/2024 13:19:19 - INFO - pecos.xmc.xtransformer.matcher - Predict on input text tensors(torch.Size([14146, 256])) in OVA mode
05/02/2024 13:19:19 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
05/02/2024 13:20:12 - INFO - pecos.xmc.xtransformer.matcher - Concatenating instance embeddings with features...
05/02/2024 13:20:12 - INFO - pecos.xmc.xtransformer.matcher - Start training concat_model of transformer matcher...
05/02/2024 13:20:24 - INFO - pecos.xmc.xtransformer.matcher - Using concat-only for transformer/concat ensemble of pred_csr
05/02/2024 13:20:26 - INFO - pecos.xmc.xtransformer.model - Fine-tuning XR-Transformer with tfn+man at level 1, nr_labels=2048, avr_M_nnz=20.49384985154814
05/02/2024 13:20:27 - INFO - pecos.xmc.xtransformer.matcher - Downloaded bert-base-uncased model from s3.
05/02/2024 13:20:38 - INFO - pecos.xmc.xtransformer.matcher - trn tensors loaded_from /scratch/slurm_tmpdir/job_23530582/tmpc0pu12t2/X_trn.pt
05/02/2024 13:20:38 - INFO - pecos.xmc.xtransformer.matcher - Continue training form given text_encoder!
05/02/2024 13:21:08 - INFO - pecos.xmc.xtransformer.matcher - Initialized transformer text_model with xlinear!
05/02/2024 13:21:08 - INFO - pecos.utils.torch_util - Setting device to cuda, number of active GPUs: 1
05/02/2024 13:21:08 - INFO - pecos.xmc.xtransformer.matcher - Start fine-tuning transformer matcher...
05/02/2024 13:21:08 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
/home/ul/ul_student/ul_ruw26/.local/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher - ***** Running training *****
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Num examples = 14146
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Num labels = 2048
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Num active labels per instance = 480
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Num Epochs = 3
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Learning Rate Schedule = linear
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Batch size = 32
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Gradient Accumulation steps = 1
05/02/2024 13:21:09 - INFO - pecos.xmc.xtransformer.matcher -   Total optimization steps = 1000
05/02/2024 13:21:31 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][    50/  1000] |   49/ 443 batches | ms/batch 318.9239 | train_loss 5.488455e-01 | lr 2.500000e-05
05/02/2024 13:21:47 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   100/  1000] |   99/ 443 batches | ms/batch 311.0779 | train_loss 5.054759e-01 | lr 5.000000e-05
05/02/2024 13:22:04 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   150/  1000] |  149/ 443 batches | ms/batch 312.8556 | train_loss 4.704902e-01 | lr 4.722222e-05
05/02/2024 13:22:20 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   200/  1000] |  199/ 443 batches | ms/batch 313.7311 | train_loss 4.521835e-01 | lr 4.444444e-05
05/02/2024 13:22:20 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpl598zjea at global_step 200 ****
05/02/2024 13:22:21 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:22:38 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   250/  1000] |  249/ 443 batches | ms/batch 314.6361 | train_loss 4.463362e-01 | lr 4.166667e-05
05/02/2024 13:22:54 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   300/  1000] |  299/ 443 batches | ms/batch 315.2146 | train_loss 4.436512e-01 | lr 3.888889e-05
05/02/2024 13:23:11 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   350/  1000] |  349/ 443 batches | ms/batch 316.0411 | train_loss 4.402670e-01 | lr 3.611111e-05
05/02/2024 13:23:28 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   3][   400/  1000] |  399/ 443 batches | ms/batch 316.4731 | train_loss 4.377776e-01 | lr 3.333333e-05
05/02/2024 13:23:28 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpl598zjea at global_step 400 ****
05/02/2024 13:23:28 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:23:49 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   450/  1000] |    6/ 443 batches | ms/batch 310.8012 | train_loss 4.347412e-01 | lr 3.055556e-05
05/02/2024 13:24:06 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   500/  1000] |   56/ 443 batches | ms/batch 316.1576 | train_loss 4.307821e-01 | lr 2.777778e-05
05/02/2024 13:24:23 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   550/  1000] |  106/ 443 batches | ms/batch 316.7101 | train_loss 4.308422e-01 | lr 2.500000e-05
05/02/2024 13:24:40 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   600/  1000] |  156/ 443 batches | ms/batch 317.0587 | train_loss 4.280143e-01 | lr 2.222222e-05
05/02/2024 13:24:40 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpl598zjea at global_step 600 ****
05/02/2024 13:24:40 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:24:57 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   650/  1000] |  206/ 443 batches | ms/batch 316.9665 | train_loss 4.278731e-01 | lr 1.944444e-05
05/02/2024 13:25:14 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   700/  1000] |  256/ 443 batches | ms/batch 317.1955 | train_loss 4.280375e-01 | lr 1.666667e-05
05/02/2024 13:25:31 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   750/  1000] |  306/ 443 batches | ms/batch 317.3539 | train_loss 4.263856e-01 | lr 1.388889e-05
05/02/2024 13:25:48 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   800/  1000] |  356/ 443 batches | ms/batch 317.4324 | train_loss 4.255960e-01 | lr 1.111111e-05
05/02/2024 13:25:48 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpl598zjea at global_step 800 ****
05/02/2024 13:25:48 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:26:05 - INFO - pecos.xmc.xtransformer.matcher - | [   2/   3][   850/  1000] |  406/ 443 batches | ms/batch 317.3956 | train_loss 4.246204e-01 | lr 8.333333e-06
05/02/2024 13:26:26 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][   900/  1000] |   13/ 443 batches | ms/batch 311.6463 | train_loss 4.241192e-01 | lr 5.555556e-06
05/02/2024 13:26:43 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][   950/  1000] |   63/ 443 batches | ms/batch 317.1001 | train_loss 4.224146e-01 | lr 2.777778e-06
05/02/2024 13:27:00 - INFO - pecos.xmc.xtransformer.matcher - | [   3/   3][  1000/  1000] |  113/ 443 batches | ms/batch 317.1206 | train_loss 4.191466e-01 | lr 0.000000e+00
05/02/2024 13:27:00 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpl598zjea at global_step 1000 ****
05/02/2024 13:27:00 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:27:01 - INFO - pecos.xmc.xtransformer.matcher - Reload the best checkpoint from /scratch/slurm_tmpdir/job_23530582/tmpl598zjea
05/02/2024 13:27:02 - INFO - pecos.xmc.xtransformer.matcher - Predict with csr_codes_next((14146, 2048)) with avr_nnz=320.0
05/02/2024 13:27:02 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
05/02/2024 13:27:56 - INFO - pecos.xmc.xtransformer.matcher - Concatenating instance embeddings with features...
05/02/2024 13:27:57 - INFO - pecos.xmc.xtransformer.matcher - Start training concat_model of transformer matcher...
05/02/2024 13:28:20 - INFO - pecos.xmc.xtransformer.matcher - Using concat-only for transformer/concat ensemble of pred_csr
05/02/2024 13:28:23 - INFO - pecos.xmc.xtransformer.model - Fine-tuning XR-Transformer with tfn+man at level 2, nr_labels=30938, avr_M_nnz=26.134949809133325
05/02/2024 13:28:25 - INFO - pecos.xmc.xtransformer.matcher - Downloaded bert-base-uncased model from s3.
05/02/2024 13:28:35 - INFO - pecos.xmc.xtransformer.matcher - trn tensors loaded_from /scratch/slurm_tmpdir/job_23530582/tmpc0pu12t2/X_trn.pt
05/02/2024 13:28:35 - INFO - pecos.xmc.xtransformer.matcher - Continue training form given text_encoder!
05/02/2024 13:29:00 - INFO - pecos.xmc.xtransformer.matcher - Initialized transformer text_model with xlinear!
05/02/2024 13:29:00 - INFO - pecos.utils.torch_util - Setting device to cuda, number of active GPUs: 1
05/02/2024 13:29:00 - INFO - pecos.xmc.xtransformer.matcher - Start fine-tuning transformer matcher...
05/02/2024 13:29:00 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
/home/ul/ul_student/ul_ruw26/.local/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher - ***** Running training *****
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Num examples = 14146
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Num labels = 30938
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Num active labels per instance = 622
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Num Epochs = 1
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Learning Rate Schedule = linear
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Batch size = 32
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Gradient Accumulation steps = 1
05/02/2024 13:29:01 - INFO - pecos.xmc.xtransformer.matcher -   Total optimization steps = 400
05/02/2024 13:29:22 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][    50/   400] |   49/ 443 batches | ms/batch 309.1473 | train_loss 4.409003e-01 | lr 2.500000e-05
05/02/2024 13:29:38 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   100/   400] |   99/ 443 batches | ms/batch 310.8323 | train_loss 4.405455e-01 | lr 5.000000e-05
05/02/2024 13:29:55 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   150/   400] |  149/ 443 batches | ms/batch 312.5670 | train_loss 4.430851e-01 | lr 4.166667e-05
05/02/2024 13:30:11 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   200/   400] |  199/ 443 batches | ms/batch 313.5733 | train_loss 4.332826e-01 | lr 3.333333e-05
05/02/2024 13:30:11 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpz31rlqzl at global_step 200 ****
05/02/2024 13:30:12 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:30:29 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   250/   400] |  249/ 443 batches | ms/batch 314.4525 | train_loss 4.338659e-01 | lr 2.500000e-05
05/02/2024 13:30:46 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   300/   400] |  299/ 443 batches | ms/batch 315.2821 | train_loss 4.260956e-01 | lr 1.666667e-05
05/02/2024 13:31:02 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   350/   400] |  349/ 443 batches | ms/batch 316.1202 | train_loss 4.315128e-01 | lr 8.333333e-06
05/02/2024 13:31:19 - INFO - pecos.xmc.xtransformer.matcher - | [   1/   1][   400/   400] |  399/ 443 batches | ms/batch 316.5089 | train_loss 4.317119e-01 | lr 0.000000e+00
05/02/2024 13:31:19 - INFO - pecos.xmc.xtransformer.matcher - | **** saving model (avg_prec=0) to /scratch/slurm_tmpdir/job_23530582/tmpz31rlqzl at global_step 400 ****
05/02/2024 13:31:20 - INFO - pecos.xmc.xtransformer.matcher - -----------------------------------------------------------------------------------------
05/02/2024 13:31:21 - INFO - pecos.xmc.xtransformer.matcher - Reload the best checkpoint from /scratch/slurm_tmpdir/job_23530582/tmpz31rlqzl
05/02/2024 13:31:21 - INFO - pecos.xmc.xtransformer.matcher - Predict with csr_codes_next((14146, 30938)) with avr_nnz=302.2745652481267
05/02/2024 13:31:21 - INFO - pecos.xmc.xtransformer.module - Constructed XMCTextTensorizer, tokenized=True, len=14146
05/02/2024 13:32:15 - INFO - pecos.xmc.xtransformer.model - Constructed instance feature matrix with shape=(14146, 102706)
05/02/2024 13:32:20 - INFO - pecos.xmc.xtransformer.model - Hierarchical label tree for ranker: [8, 128, 2048, 30938]
05/02/2024 13:32:20 - INFO - pecos.xmc.xtransformer.model - Start training ranker...
05/02/2024 13:32:20 - INFO - pecos.xmc.base - Training Layer 0 of 4 Layers in HierarchicalMLModel, neg_mining=tfn..
05/02/2024 13:32:22 - INFO - pecos.xmc.base - Training Layer 1 of 4 Layers in HierarchicalMLModel, neg_mining=tfn..
05/02/2024 13:32:27 - INFO - pecos.xmc.base - Training Layer 2 of 4 Layers in HierarchicalMLModel, neg_mining=tfn..
05/02/2024 13:32:41 - INFO - pecos.xmc.base - Training Layer 3 of 4 Layers in HierarchicalMLModel, neg_mining=tfn+man..
05/02/2024 13:34:37 - INFO - pecos.xmc.xtransformer.model - Parameters saved to ./trained-models/xr_model_wiki10-31k/param.json
05/02/2024 13:34:41 - INFO - pecos.xmc.xtransformer.model - Model saved to ./trained-models/xr_model_wiki10-31k

============================= JOB FEEDBACK =============================

NodeName=uc2n912
Job ID: 23530582
Cluster: uc2
User/Group: ul_ruw26/ul_student
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 01:34:49
CPU Efficiency: 23.72% of 06:39:44 core-walltime
Job Wall-clock time: 00:24:59
Memory Utilized: 21.84 GB
Memory Efficiency: 89.45% of 24.41 GB
